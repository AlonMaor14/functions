{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embeddings Serverless Function\n",
    "This notebook presents deployment of pretrained BERT model that outputs embeddings for given textual sequences as a serverless function. Embeddings are meaningful, contextual representations of text in the form of ndarrays that are used frequently as input to various learning tasks in the field of NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio\n",
    "from nuclio import build_file\n",
    "import json\n",
    "import pickle\n",
    "from test import init_context, handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/User/.pythonlibs/jupyter-alonm/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "context = nuclio.Context()\n",
    "event = nuclio.Event(body=json.dumps(['John loves Mary']))\n",
    "init_context(context)\n",
    "outputs = pickle.loads(handler(context, event))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good chance to view the outputs of this BERT model. It gives two different outputs. The first is a contextual embedding for each token in the input sequence and the second is a pooled embedding for the complete sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings per token shape: (1, 5, 768), pooled embeddings shape: (1, 768)\n"
     ]
    }
   ],
   "source": [
    "print(f'embeddings per token shape: {outputs[0].shape}, pooled embeddings shape: {outputs[1].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen both outputs share first dimension size of 1. This corresponds to the single sequence we passed as input, \"John loves Mary\". The last dimension for both is of size 768 which is the embedding dimension for this default configuration of bert. Note that the first input has an intermediate dimension of size 5 that corresponds to the number of tokens in the input sequence after addtion of two special tokens marking beginning and end of a sequence by the tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy as serverless function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-02-15 08:05:23,190 [warning] Unable to parse server or client version. Assuming compatible: {'server_version': 'X', 'client_version': '0.6.0'}\n",
      "> 2021-02-15 08:05:26,583 [info] function spec saved to path: function.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f49b74f7c90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function\n",
    "fn = code_to_function(\"bert_embeddings\", kind=\"nuclio\",\n",
    "                      description=\"Get BERT based embeddings for given text\",\n",
    "                      categories=[\"NLP\", \"BERT\", \"embeddings\"],\n",
    "                      labels = {\"author\": \"roye\", \"framework\": \"pytorch\"},\n",
    "                      code_output='.')\n",
    "\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-02-15 08:05:26,595 [info] Starting remote function deploy\n",
      "2021-02-15 08:05:26  (info) Deploying function\n",
      "2021-02-15 08:05:26  (info) Building\n",
      "2021-02-15 08:05:26  (info) Staging files and preparing base images\n",
      "2021-02-15 08:05:26  (info) Building processor image\n",
      "2021-02-15 08:05:27  (info) Build complete\n",
      "Failed to deploy. Details:\n",
      "Caught unhandled exception while initializing [err=\"No module named 'nuclio'\" || traceback=\"Traceback (most recent call last):\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 350, in run_wrapper\n",
      "    args.trigger_name)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 57, in __init__\n",
      "    self._entrypoint = self._load_entrypoint_from_handler(handler)\n",
      "  File \"/opt/nuclio/_nuclio_wrapper.py\", line 159, in _load_entrypoint_from_handler\n",
      "    module = __import__(module_name)\n",
      "  File \"/opt/nuclio/bert_embeddings.py\", line 3, in <module>\n",
      "    import nuclio\n",
      "ModuleNotFoundError: No module named 'nuclio'\n",
      "\" || worker_id=\"0\"]\n",
      "> 2021-02-15 08:05:32,072 [error] Nuclio function failed to deploy\n"
     ]
    },
    {
     "ename": "RunError",
     "evalue": "cannot deploy Failed to deploy. Details:\nCaught unhandled exception while initializing [err=\"No module named 'nuclio'\" || traceback=\"Traceback (most recent call last):\n  File \"/opt/nuclio/_nuclio_wrapper.py\", line 350, in run_wrapper\n    args.trigger_name)\n  File \"/opt/nuclio/_nuclio_wrapper.py\", line 57, in __init__\n    self._entrypoint = self._load_entrypoint_from_handler(handler)\n  File \"/opt/nuclio/_nuclio_wrapper.py\", line 159, in _load_entrypoint_from_handler\n    module = __import__(module_name)\n  File \"/opt/nuclio/bert_embeddings.py\", line 3, in <module>\n    import nuclio\nModuleNotFoundError: No module named 'nuclio'\n\" || worker_id=\"0\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRunError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5716dc5bd390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nlp-servers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pythonlibs/jupyter-alonm/lib/python3.7/site-packages/mlrun/runtimes/function.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, dashboard, project, tag, verbose)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ready\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nuclio function failed to deploy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRunError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot deploy {text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRunError\u001b[0m: cannot deploy Failed to deploy. Details:\nCaught unhandled exception while initializing [err=\"No module named 'nuclio'\" || traceback=\"Traceback (most recent call last):\n  File \"/opt/nuclio/_nuclio_wrapper.py\", line 350, in run_wrapper\n    args.trigger_name)\n  File \"/opt/nuclio/_nuclio_wrapper.py\", line 57, in __init__\n    self._entrypoint = self._load_entrypoint_from_handler(handler)\n  File \"/opt/nuclio/_nuclio_wrapper.py\", line 159, in _load_entrypoint_from_handler\n    module = __import__(module_name)\n  File \"/opt/nuclio/bert_embeddings.py\", line 3, in <module>\n    import nuclio\nModuleNotFoundError: No module named 'nuclio'\n\" || worker_id=\"0\"]"
     ]
    }
   ],
   "source": [
    "addr = fn.deploy(project='nlp-servers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the function via http request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "event_data = ['the quick brown fox jumps over the lazy dog', 'Hello I am Jacob']\n",
    "resp = requests.post(addr, json=json.dumps(event_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_embeddings = pickle.loads(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'embeddings per token shape: {output_embeddings[0].shape}, pooled embeddings shape: {output_embeddings[1].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the size of the first dimension of the outputs is two since we passed in two sequences. Also the intermediate dimension of the first output is the maximal number of tokens across all input sequences. Sequences with less tokens are padded with zero values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
