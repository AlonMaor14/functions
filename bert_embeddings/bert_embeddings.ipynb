{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embeddings Serverless Function\n",
    "This notebook presents deployment of pretrained BERT model that outputs embeddings for given textual sequences as a serverless function. Embeddings are meaningful, contextual representations of text in the form of ndarrays that are used frequently as input to various learning tasks in the field of NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio\n",
    "import json\n",
    "import pickle\n",
    "from bert_embeddings import init_context, handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = nuclio.Context()\n",
    "event = nuclio.Event(body=json.dumps(['John loves Mary']))\n",
    "init_context(context)\n",
    "outputs = pickle.loads(handler(context, event))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good chance to view the outputs of this BERT model. It gives two different outputs. The first is a contextual embedding for each token in the input sequence and the second is a pooled embedding for the complete sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings per token shape: (1, 5, 768), pooled embeddings shape: (1, 768)\n"
     ]
    }
   ],
   "source": [
    "print(f'embeddings per token shape: {outputs[0].shape}, pooled embeddings shape: {outputs[1].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen both outputs share first dimension size of 1. This corresponds to the single sequence we passed as input, \"John loves Mary\". The last dimension for both is of size 768 which is the embedding dimension for this default configuration of bert. Note that the first input has an intermediate dimension of size 5 that corresponds to the number of tokens in the input sequence after addtion of two special tokens marking beginning and end of a sequence by the tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy as serverless function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-02-15 10:33:26,557 [info] function spec saved to path: bert_embeddings.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f23ae137d90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function\n",
    "fn = code_to_function(\"bert_embeddings\", kind=\"nuclio\",\n",
    "                      filename=\"bert_embeddings.py\",\n",
    "                      description=\"Get BERT based embeddings for given text\",\n",
    "                      categories=[\"NLP\", \"BERT\", \"embeddings\"],\n",
    "                      labels = {\"author\": \"roye\", \"framework\": \"pytorch\"},\n",
    "                      requirements=[\"torch==1.6.0\", \"transformers==3.0.1\", \"nuclio\"],)\n",
    "\n",
    "fn.export(\"bert_embeddings.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-02-15 10:33:26,571 [info] Starting remote function deploy\n",
      "2021-02-15 10:33:26  (info) Deploying function\n",
      "2021-02-15 10:33:26  (info) Building\n",
      "2021-02-15 10:33:26  (info) Staging files and preparing base images\n",
      "2021-02-15 10:33:26  (info) Building processor image\n",
      "2021-02-15 10:33:28  (info) Build complete\n",
      "> 2021-02-15 10:33:47,608 [info] function deployed, address=default-tenant.app.vmdev36.lab.iguazeng.com:30921\n"
     ]
    }
   ],
   "source": [
    "addr = fn.deploy(project='nlp-servers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the function via http request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "event_data = ['the quick brown fox jumps over the lazy dog', 'Hello I am Jacob']\n",
    "resp = requests.post(addr, json=json.dumps(event_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_embeddings = pickle.loads(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings per token shape: (2, 11, 768), pooled embeddings shape: (2, 768)\n"
     ]
    }
   ],
   "source": [
    "print(f'embeddings per token shape: {output_embeddings[0].shape}, pooled embeddings shape: {output_embeddings[1].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the size of the first dimension of the outputs is two since we passed in two sequences. Also the intermediate dimension of the first output is the maximal number of tokens across all input sequences. Sequences with less tokens are padded with zero values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
